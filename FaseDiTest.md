# Fase di test
Il collaudo del software o testing è un procedimento che fa parte del ciclo di vita del software e che permette di individuare eventuali errori di correttezza, completezza e affidabilità delle componenti. Questa fase consiste nell'eseguire il software da collaudare e valutare la sua correttezza e se rispetta i requisiti.
## Malfunzionamenti e difetti
È importante distinguere i malfunzionamenti del software e i difetti del software.
- **Malfunzionamenti**: un malfunzionamento è l'accumulazione di diversi difetti che portano ad comportamento scorretto del software con una risultante perdita di informazioni in moduli critici rendendo il sistema non responsivo. Il malfunzionamento viene di solito scoperto dagli utenti finali che non posson usufruire del servizio offerto dal software. Il software avrà una certa probabilità di malfunzionamento. La soglia di probabilità di malfunzionamento accettabile dipende dal tipo di applicazione. Applicazioni "life-critical" (quelli usati in ambiti in cui vite umane dipendono da esso) devono avere probabilità di malfunzionamento estremamente basse.
- **Difetto**: un difetto è una sequenza di istruzioni, sorgenti o eseguibili che, quando eseguita con particolari dati in input, genera un malfunzionamento. Detto in parole povere si ha un malfunzionamento del software solo quando viene eseguito il codice che contiene un difetto e solo se i dati in input sono tali da evidenziare l'errore. Un software, quindi, ha un difetto se il suo comportamento non è conforme alle specifiche. Si hanno diversi tipi difetti:
	- **difetti di specifiche**: la descrizione delle specifiche del software è ambigua, contraddittoria oppure imprecisa.
	- **difetti di design**: le componenti del software e le loro interazioni sono progettate non correttamente.
	- **difetti di codice**: sono errori dovuti ad una sbagliata implementazione del codice. È difficile distinguere difetti di design e difetti di codice. Errori nel codice sorgente possono anche essere rilevati se il codice viene compilato ed eseguito con particolari compilatori o su particolari piattaforme, per questo motivo è importante testare il software su diverse piattaforme e con diversi compilatori. 
	- **difetti di test**: errori introdotti nella fase di testing del software.
Per rilevare il maggior numero possibile di difetti bisogna collaudare esaustivamente il software prevedendo il maggior numero possibile di casi d'uso.
## Verifica e validazione
La fase di verifica e validazione serve ad accettare che il software rispecchi i requisiti e che li rispetti nella maniera dovuta. La **verifica** serve a stabilire che il software rispetti i requisiti e le specifiche, quindi ad esempio che non ci siano requisiti mancanti. La **validazione** serve ad accertare che il software faccia e sia ciò che il cliente ha realmente richiesto.

Il processo di verifica e validazione dovrebbe essere applicato ad ogni fase di sviluppo del software indipendentemente dal tipo di processo di sviluppo usato per poter eventualmente rilevare i diversi tipi di difetti che potrebbero sorgere.
## Test
Il test del software riesce a rilevare solamente la presenza di errori e non la loro assenza. Si dice che un test ha successo quando riesce a rilevare uno o più errori. Una volta rilevato l'errore si effettua il debugging cioè quella fase che consiste nella localizzazione e nella correzzione degli errori trovati durante la fase testing.

Un test è costituito da dei dati in input (**dati di test**) scelti appositamente per il testing e **casi di test** cioè una combinazione di dati input e output stimati per quei specifici dati in input; sulla base di certi dati in input ci si aspettano certi dati in output in base alle specifiche del software. Un'insieme di test viene detto **test suite**.

In base alla granularità, i test si suddividono in:
- **unit test** il cui obiettivo è testare singoli frammenti di codice. La scrittura degli unit test viene effettuata direttamente dallo sviluppatore che ha implementato la componente.
- **test di integrazione** il cui obiettivo è testare gruppi di componenti già integrati nel sistema generale o in un sottosistema del software. La scrittura dei test di integrazione viene tipicamente effettuata da un team apposito di tester e la loro progettazione è spesso responsabilità di una figura apposita.

Per dimostrare che un software sia completamente privo di difetti occorerebbe effettuate un **test esaustivo**, cioè un test che copre tutti i possibili scenari. Ad esempio per testare esaustivamente una funzione che prende in ingresso due interi bisognerebbe eseguirla per ogni coppia di valori che i due interi possono assumere, quindi $2^{32}*2^{32}$ volte. È facile capire che effettuare test esaustivi non è praticabile. Quello che si fa è scegliere con precisione e in modo opportuno solo alcune delle combinazioni di input possibili per testare il sistema.
### Strategie di test
Due delle strategie più comuni sono la strategia **black-box** e **white-box**. Con la prima il tester non ha a disposizione il codice del sistema da testare mentre con la seconda il tester ha a disposizione il codice del sistema. 

Con la strategia black-box, quindi, i test case sono progettati sulla base della descrizione del sistema ovvero partendo dalle specifiche del sistema stesso. Diventa quindi fondamentale riuscire a scegliere combinazioni di valori in input che siano significative per il sistema. Un modo per selezionare gli input per il test al sistema è ricorrere a **partizioni in classi di equivalenza**. Partizionare l'input in classi di equivalenza vuol dire ridurre le combinazioni di dati in input che si vanno a considerare per il test. Si cerca di suddividere in gruppi gli input per cui ci si aspetta che il componente effettui elaborazioni simili per ciascun membro dello stesso gruppo. Ad esempio data una funzione che lavora solo con interi compresi tra 4 e 20, si potrebbero suddividere gli input in una classe di interi minori di 4, una classe di interi compresi tra 4 e 20 e una classi di interi maggiori di 20.

Nell'approccio white-box, invece, ci si focalizza sulla struttura interna del sistema da testare, ad esempio si potrebbero preferire test che garantiscono una copertura totale del codice del sistema. L'obiettivo dei test white-box, anche detti test strutturali è quello di eseguire tutti i costrutti o possibili percorsi del programma. Un percorso all'interno del programma è una sequenza di istruzioni che vengono eseguite dall'ingresso al metodo fino all'uscita dal metodo. Per capire quanti percorsi sono presenti in un frammento di codice e quindi quanti test bisogna scrivere si utilizza la [**complessità ciclomatica**](./MetricheDelSoftware.md). Rappresentando il programma con un grafo di flusso dove i nodi sono istruzioni del programma e gli archi flussi di controllo si può calcolare la complessità ciclomatica con la formula *numero di archi - numero di nodi + 2*. Un altro metodo per calcolare la complessità ciclomatica è contare quante istruzioni condizionali ci sono nel codice e aggiungere 1.
## Test di integrazione
I test di integrazione, come già detto, sono test eseguiti sul sistema completo o su un sottosistema del software. Solitamente i test di integrazione sono di tipo black-box e devono basarsi sulle specifiche di funzionamento del sistema. Uno dei principali problemi del test di integrazione è la difficoltà nel localizzare l'errore all'interno del sistema. Effettuare test di integrazione in modo incrementale ogni volta che si aggiunge una nuova componente al sistema restringe la posizione in cui gli errori possono trovarsi rendendo più semplice la loro localizzazione all'interno del codice.

I test di integrazione possono essere principalmente di due tipi:
- **top down**: l'integrazione delle componenti parte dall'alto; prima si integrano componenti di alto livello per poi passare all'integrazione delle componenti di basso livello. Questo approccio, grazie al punto di vista di alto livello, permette di scoprire errori nell'architettura generale del sistema e permette anche di creare velocemente dei prototipi parzialmente funzionali del software.
- **bottom up**: si integrano prima i componenti di basso livello che hanno poche dipendenze e successivamente si passa all'integrazione di componenti di alto livello che presentano diverse dipendenze. Questa tecnica rende la scrittura dei test più semplice.
Nella pratica si utilizza una combinazione dei due approcci.
## Test sotto stress
I sotto stress, come dice il nome, analizzano il comportamento del software quando il carico è massimo. L'esecuzione del sistema oltre i limiti di carico stimati non dovrebbe risultare in un completo fallimento dell'esecuzione. Sono particolarmente importanti per grossi sistemi distribuiti che soddisfano migliaia di richieste dalla rete.
## Testing manuale
I test manuali sono test che accertano la correttezza di funzionalità di alto livello che, ad esempio, richiedono l'interazione con l'utente. Viene spesso utilizzato quando l'automazione del test richiede troppe risorse in termini di tempo o in termini economici.
## Testing automatico
In contrapposizione al testing manuale esiste il testing automatico che ha il vantaggio di poter essere rieseguito più volte senza la necessità dell'intervento umano. Esistono strumenti che permettono di automatizzare test che solitamente sono manuali. Questi, tramite macro, script o programmi appositi mimano l'interazione che un utente potrebbe avere con il sistema. Il problema di questi strumenti è che non sono molto robusti perché sono strettamente collegati alle interfacce del sistema che potrebbero cambiare nel tempo.
## Test regressivi
Fare test regressivo vuol dire effettuare tutti i test scritti fino a quel momento ogni volta che viene aggiunta una nuova componente al sistema. Questa tecnica permette accertarsi che l'aggiunta della nuova componente non faccia emergere nuovi bug nel sistema o faccia riemergere vecchi bug già sistemati. 